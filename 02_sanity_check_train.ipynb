{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a10ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import av  # pip install av\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    VideoMAEForVideoClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "import evaluate  # pip install evaluate\n",
    "\n",
    "# load environment variables with dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5398097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5df0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Point this at the Olympic Boxing dataset directory\n",
    "\n",
    "# Pretrained VideoMAE base (self-supervised on K400)\n",
    "model_name = \"MCG-NJU/videomae-base\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(LABEL2ID),\n",
    "    label2id=LABEL2ID,\n",
    "    id2label=ID2LABEL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79ab45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "# check for cuda\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ede674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxingDataset(Dataset):\n",
    "    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "    std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "    \n",
    "    train_paths = []\n",
    "    val_paths = []\n",
    "    test_paths = []\n",
    "    for label in os.listdir(\"preprocessed_clips_2\"):\n",
    "        paths = (lambda x: [f\"preprocessed_clips_2/{x}/{p}\" for p in os.listdir(f\"preprocessed_clips_2/{x}\")])(label)\n",
    "        paths_count = len(paths)\n",
    "        train_ind = math.floor(paths_count * 0.8)\n",
    "        val_ind = train_ind + math.floor(paths_count * 0.1)\n",
    "        test_ind = val_ind + math.floor(paths_count * 0.1)\n",
    "        train_paths.extend(paths[:train_ind])\n",
    "        val_paths.extend(paths[train_ind:val_ind])\n",
    "        test_paths.extend(paths[val_ind:])\n",
    "        \n",
    "    def __init__(self, split: str):\n",
    "        self.split = split\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.split == \"train\":\n",
    "            return len(self.train_paths)\n",
    "        elif self.split == \"val\":\n",
    "            return len(self.val_paths)\n",
    "        elif self.split == \"test\":\n",
    "            return len(self.test_paths)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {self.split}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"train\":\n",
    "            path = self.train_paths[idx]\n",
    "        elif self.split == \"val\":\n",
    "            path = self.val_paths[idx]\n",
    "        elif self.split == \"test\":\n",
    "            path = self.test_paths[idx]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {self.split}\")\n",
    "        \n",
    "        clip = np.load(path)\n",
    "        \n",
    "        # convert to float and scale to 0-1\n",
    "        clip = clip.astype(np.float32) / 255.0\n",
    "        \n",
    "        # image net mean/std\n",
    "        clip = (clip - self.mean) / self.std\n",
    "        \n",
    "        #reorder to (T,C,H,W)\n",
    "        clip = clip.transpose(0,3,1,2)\n",
    "        \n",
    "        #convert to tensor\n",
    "        clip = torch.from_numpy(clip)\n",
    "        \n",
    "        return {\n",
    "            \"pixel_values\": clip,\n",
    "            \"labels\": torch.tensor(LABEL2ID[path.split(\"/\")[-2]], dtype=torch.long) \n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e6d96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'LHHP': 2097,\n",
       "         'RHHP': 1077,\n",
       "         'LHMP': 993,\n",
       "         'RHMP': 624,\n",
       "         'LHBlP': 476,\n",
       "         'RHBP': 234,\n",
       "         'RHBlP': 228,\n",
       "         'LHBP': 227})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "def label_from_path(p): return p.split(\"/\")[-2]\n",
    "\n",
    "Counter(map(label_from_path, BoxingDataset.train_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25917ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'LHHP': 262,\n",
       "         'RHHP': 134,\n",
       "         'LHMP': 124,\n",
       "         'RHMP': 78,\n",
       "         'LHBlP': 59,\n",
       "         'RHBP': 29,\n",
       "         'LHBP': 28,\n",
       "         'RHBlP': 28})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(map(label_from_path, BoxingDataset.val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b171cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BoxingDataset(\n",
    "    split=\"train\",\n",
    ")\n",
    "val_dataset = BoxingDataset(\n",
    "    split=\"val\",\n",
    ")\n",
    "test_dataset = BoxingDataset(\n",
    "    split=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FACTS used batch_size=4, grad_accum=2, warmup_ratio=0.1, epochs=10\n",
    "# Learning rate is not rendered in the HTML; start with 1e-4 and tune around it.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./facts-boxing-videomae\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=8, \n",
    "    gradient_accumulation_steps=2,  # effective batch size 8\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.05,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"wandb\",  # or \"wandb\"/\"tensorboard\"\n",
    "    dataloader_num_workers=4,        # ADD THIS - use multiple workers\n",
    "    dataloader_pin_memory=True,      # ADD THIS - faster CPU->GPU transfer\n",
    "    dataloader_prefetch_factor=2, \n",
    ")\n",
    "\n",
    "data_collator = VideoDataCollator()\n",
    "\n",
    "train_labels = [LABEL2ID[path.split(\"/\")[-2]] for path in BoxingDataset.train_paths]\n",
    "\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',\n",
    "#     classes=np.arange(len(LABEL2ID)),\n",
    "#     y=np.array(train_labels)  # Ensure it's a numpy array\n",
    "# )\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a309f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_counts = np.bincount(train_labels)\n",
    "# sample_weights = 1.0 / class_counts[train_labels]\n",
    "\n",
    "# sampler = torch.utils.data.WeightedRandomSampler(\n",
    "#     sample_weights,                                              \n",
    "#     len(sample_weights), \n",
    "#     replacement=True\n",
    "# )\n",
    "# sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0d03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# sample_counts = defaultdict(int)\n",
    "# for i in range(10000):\n",
    "#     sampled_idx = random.choices(train_labels, weights=sample_weights, k=1)[0]\n",
    "#     sample_counts[sampled_idx] += 1\n",
    "\n",
    "# # use matplotlib to plot the distribution\n",
    "\n",
    "# plt.bar(sample_counts.keys(), sample_counts.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c704977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UniformSamplerTrainer(Trainer):\n",
    "#     def __init__(self, *args, train_sampler=None, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.train_sampler = train_sampler\n",
    "        \n",
    "#     def _get_train_sampler(self, train_dataset: Dataset | None = None):\n",
    "#         if train_dataset is None:\n",
    "#             train_dataset = self.train_dataset\n",
    "            \n",
    "#         if train_dataset is None or not has_length(train_dataset):\n",
    "#             return None\n",
    "        \n",
    "#         if self.train_sampler is not None:\n",
    "#             return self.train_sampler\n",
    "        \n",
    "#         return super()._get_train_sampler(train_dataset)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5580d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnkosik11\u001b[0m (\u001b[33mnkosik11-hobby\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/wandb/run-20251204_214817-axvx5j4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nkosik11-hobby/facts-classifier/runs/axvx5j4y' target=\"_blank\">New Preprocessing - Sanity Check</a></strong> to <a href='https://wandb.ai/nkosik11-hobby/facts-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nkosik11-hobby/facts-classifier' target=\"_blank\">https://wandb.ai/nkosik11-hobby/facts-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nkosik11-hobby/facts-classifier/runs/axvx5j4y' target=\"_blank\">https://wandb.ai/nkosik11-hobby/facts-classifier/runs/axvx5j4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:25, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.7302090231577555, metrics={'train_runtime': 28.0478, 'train_samples_per_second': 40.645, 'train_steps_per_second': 5.348, 'total_flos': 1.4205896420386406e+18, 'train_loss': 0.7302090231577555, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_NAME\"] = \"New Preprocessing - Sanity Check\"\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751fcb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 0.046778421849012375, 'eval_accuracy': 0.9736842105263158, 'eval_macro_f1': 0.9707792207792207, 'eval_f1_LHHP': 1.0, 'eval_precision_LHHP': 1.0, 'eval_recall_LHHP': 1.0, 'eval_f1_RHHP': 1.0, 'eval_precision_RHHP': 1.0, 'eval_recall_RHHP': 1.0, 'eval_f1_LHMP': 1.0, 'eval_precision_LHMP': 1.0, 'eval_recall_LHMP': 1.0, 'eval_f1_RHMP': 0.8571428571428571, 'eval_precision_RHMP': 1.0, 'eval_recall_RHMP': 0.75, 'eval_f1_LHBlP': 1.0, 'eval_precision_LHBlP': 1.0, 'eval_recall_LHBlP': 1.0, 'eval_f1_RHBlP': 1.0, 'eval_precision_RHBlP': 1.0, 'eval_recall_RHBlP': 1.0, 'eval_f1_LHBP': 1.0, 'eval_precision_LHBP': 1.0, 'eval_recall_LHBP': 1.0, 'eval_f1_RHBP': 0.9090909090909091, 'eval_precision_RHBP': 0.8333333333333334, 'eval_recall_RHBP': 1.0, 'eval_runtime': 0.8248, 'eval_samples_per_second': 46.07, 'eval_steps_per_second': 6.062, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate on test split\n",
    "test_metrics = trainer.evaluate(test_dataset)\n",
    "print(\"Test metrics:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c80814",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
